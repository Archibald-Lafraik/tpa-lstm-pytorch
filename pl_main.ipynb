{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import lightning.pytorch as pl\n",
    "from lightning.pytorch.loggers import WandbLogger\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from statsmodels.tsa.api import VAR\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from model import TPALSTM\n",
    "from other_models import LSTM\n",
    "import pandas as pd\n",
    "from dataset import ElectricityDataModule\n",
    "from util import RSE, CORR\n",
    "from lstnet import LSTNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = np.load('data/kbest_dataset.npy')\n",
    "num_features = data_df.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_features(best_f_idx, worst_f_idx):\n",
    "    data = np.load('data/dataset_norm.npy')\n",
    "    X = data[:, :-1]\n",
    "    y = data[:, -1]\n",
    "    kbest = SelectKBest(k=worst_f_idx).fit(X, y)\n",
    "    features = kbest.get_support(indices=True)[best_f_idx:]\n",
    "\n",
    "    custom_data = np.concatenate((X[:, features], y[:, None]), axis=1)\n",
    "    np.save(\"data/custom_dataset.npy\", custom_data)\n",
    "    return custom_data\n",
    "\n",
    "custom_data = choose_features(best_f_idx=0, worst_f_idx =30)\n",
    "num_features = custom_data.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_splits = {\n",
    "    \"train\": 0.7,\n",
    "    \"val\": 0.15,\n",
    "    \"predict\": 0.15\n",
    "}\n",
    "\n",
    "pred_horizon = 1\n",
    "\n",
    "elec_dm = ElectricityDataModule(\n",
    "    dataset_splits=data_splits,\n",
    "    batch_size=128,\n",
    "    window_size=24,\n",
    "    pred_horizon=pred_horizon,\n",
    "    data_style=\"custom\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_name = f\"{pred_horizon}ts-kbest30-mlp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "hid_size = 64\n",
    "n_layers = 1\n",
    "num_filters = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LSTM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb_logger_stacked_lstm = WandbLogger(\n",
    "    name=f'{run_name}-Stacked-LSTM-{hid_size}-{n_layers}l',\n",
    "    save_dir='logs',\n",
    "    project='Time-Series project',\n",
    "    log_model=True\n",
    ")\n",
    "\n",
    "checkpoint_loss_stacked_lstm = ModelCheckpoint(\n",
    "    dirpath=f\"checkpoints/{run_name}/Stacked-LSTM\",\n",
    "    filename='BEST-{epoch}-{val_loss:.3f}-{val_score:.3f}',\n",
    "    save_top_k=1,\n",
    "    monitor=\"val/loss\",\n",
    "    mode=\"min\"\n",
    ")\n",
    "\n",
    "stacked_lstm_trainer = pl.Trainer(\n",
    "    max_epochs=80,\n",
    "    accelerator='gpu',\n",
    "    callbacks=[checkpoint_loss_stacked_lstm],\n",
    "    strategy='auto',\n",
    "    devices=1,\n",
    "    logger=wandb_logger_stacked_lstm\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_lstm = LSTM(\n",
    "    input_size=num_features,\n",
    "    lstm_hid_size=hid_size,\n",
    "    linear_hid_size=100,\n",
    "    output_horizon=pred_horizon,\n",
    "    n_layers=n_layers\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_lstm_trainer.fit(stacked_lstm, elec_dm)\n",
    "wandb_logger_stacked_lstm.experiment.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elec_dm.setup(\"predict\")\n",
    "\n",
    "model_path = \"checkpoints/4ts-kbest/Stacked-LSTM/BEST-epoch=73-val_loss=0.000-val_score=0.000.ckpt\"\n",
    "stacked_lstm = LSTM.load_from_checkpoint(model_path)\n",
    "\n",
    "pred_dl = elec_dm.predict_dataloader()\n",
    "\n",
    "y_pred = stacked_lstm_trainer.predict(stacked_lstm, pred_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_idx = 0\n",
    "for i, batch in enumerate(pred_dl):\n",
    "    inputs, labels = batch\n",
    "    X, ytrue = inputs[batch_idx][:, -1], labels[batch_idx].squeeze()\n",
    "    ypred = y_pred[i][batch_idx].squeeze()\n",
    "    \n",
    "    X = X.cpu().numpy()\n",
    "    ytrue = ytrue.cpu().numpy()\n",
    "    ypred = ypred.cpu().numpy()\n",
    "    # print(inputs.shape)\n",
    "    # print(labels.shape, y_pred[i].shape)\n",
    "\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    plt.plot(range(0, 24), X, label=\"Input\")\n",
    "    plt.scatter(range(24, 24 + pred_horizon), ytrue, color='red', label=\"True price\")\n",
    "    plt.scatter(range(24, 24 + pred_horizon), ypred, color='green', label=\"Predicted price\")\n",
    "    plt.legend()\n",
    "    plt.title(\"Stacked-LSTM\")\n",
    "    plt.show()\n",
    "\n",
    "    if i == 3:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TPA-LSTM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# name = f'{run_name}-TPA-LSTM-{hid_size}-{num_filters}f-{n_layers}l'\n",
    "name = f'{run_name}-TPA-LSTM'\n",
    "\n",
    "wandb_logger_tpalstm = WandbLogger(\n",
    "    name=name,\n",
    "    save_dir='logs',\n",
    "    project='Time-Series project',\n",
    "    log_model=True\n",
    ")\n",
    "\n",
    "checkpoint_loss_tpalstm = ModelCheckpoint(\n",
    "    dirpath=f\"checkpoints/{run_name}/TPA-LSTM\",\n",
    "    filename=name,\n",
    "    save_top_k=1,\n",
    "    monitor=\"val/loss\",\n",
    "    mode=\"min\"\n",
    ")\n",
    "\n",
    "tpalstm_trainer = pl.Trainer(\n",
    "    max_epochs=60,\n",
    "    # accelerator='gpu',\n",
    "    callbacks=[checkpoint_loss_tpalstm],\n",
    "    strategy='auto',\n",
    "    devices=1,\n",
    "    logger=wandb_logger_tpalstm\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tpa_lstm = TPALSTM(\n",
    "    input_size=num_features,\n",
    "    hidden_size=hid_size,\n",
    "    output_horizon=pred_horizon,\n",
    "    num_filters=num_filters,\n",
    "    obs_len=24,\n",
    "    n_layers=n_layers,\n",
    "    lr=1e-3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tpalstm_trainer.fit(tpa_lstm, elec_dm)\n",
    "wandb_logger_tpalstm.experiment.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elec_dm.setup(\"predict\")\n",
    "\n",
    "model_path = f\"checkpoints/{run_name}/TPA-LSTM/BEST-epoch=35-val_loss=0.000-val_score=0.000.ckpt\"\n",
    "tpa_lstm = TPALSTM.load_from_checkpoint(model_path)\n",
    "\n",
    "pred_dl = elec_dm.predict_dataloader()\n",
    "\n",
    "y_pred = tpalstm_trainer.predict(tpa_lstm, pred_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_idx = 0\n",
    "for i, batch in enumerate(pred_dl):\n",
    "    inputs, labels = batch\n",
    "    X, ytrue = inputs[batch_idx][:, -1], labels[batch_idx].squeeze()\n",
    "    ypred = y_pred[i][batch_idx].squeeze()\n",
    "    \n",
    "    X = X.cpu().numpy()\n",
    "    ytrue = ytrue.cpu().numpy()\n",
    "    ypred = ypred.cpu().numpy()\n",
    "    # print(inputs.shape)\n",
    "    # print(labels.shape, y_pred[i].shape)\n",
    "\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    plt.plot(range(0, 24), X, label=\"Input\")\n",
    "    plt.scatter(range(24, 24 + pred_horizon), ytrue, color='red', label=\"True price\")\n",
    "    plt.scatter(range(24, 24 + pred_horizon), ypred, color='green', label=\"Predicted price\")\n",
    "    plt.legend()\n",
    "    plt.title(\"TPA-LSTM\")\n",
    "    plt.show()\n",
    "\n",
    "    if i == 3:\n",
    "        break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LSTNet**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mfraikinarchie\u001b[0m (\u001b[33mmva-data-challenge\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>logs/wandb/run-20230327_102550-k7e87r0p</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/mva-data-challenge/Time-Series%20project/runs/k7e87r0p' target=\"_blank\">1ts-kbest30-mlp-LSTNet</a></strong> to <a href='https://wandb.ai/mva-data-challenge/Time-Series%20project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/mva-data-challenge/Time-Series%20project' target=\"_blank\">https://wandb.ai/mva-data-challenge/Time-Series%20project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/mva-data-challenge/Time-Series%20project/runs/k7e87r0p' target=\"_blank\">https://wandb.ai/mva-data-challenge/Time-Series%20project/runs/k7e87r0p</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "name = f'{run_name}-LSTNet'\n",
    "\n",
    "wandb_logger_lstnet = WandbLogger(\n",
    "    name=name,\n",
    "    save_dir='logs',\n",
    "    project='Time-Series project',\n",
    "    log_model=True\n",
    ")\n",
    "\n",
    "checkpoint_loss_lstnet = ModelCheckpoint(\n",
    "    dirpath=f\"checkpoints/{run_name}/LSTNet\",\n",
    "    filename=name,\n",
    "    save_top_k=1,\n",
    "    monitor=\"val/loss\",\n",
    "    mode=\"min\"\n",
    ")\n",
    "\n",
    "lstnet_trainer = pl.Trainer(\n",
    "    max_epochs=60,\n",
    "    # accelerator='gpu',\n",
    "    callbacks=[checkpoint_loss_lstnet],\n",
    "    strategy='auto',\n",
    "    devices=1,\n",
    "    logger=wandb_logger_lstnet\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstnet = LSTNet(\n",
    "    num_features=31,\n",
    "    window_size=24,\n",
    "    conv1_out_channels=32, \n",
    "    conv1_kernel_height=6,\n",
    "    recc1_out_channels=64, \n",
    "    skip=3, \n",
    "    skip_reccs_out_channels=6, \n",
    "    hw_window_size=7,\n",
    "    output_fun=\"sigmoid\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/damso/opt/anaconda3/envs/venv/lib/python3.8/site-packages/lightning/pytorch/callbacks/model_checkpoint.py:612: UserWarning: Checkpoint directory /Users/damso/MVA/TimeSeries/tpa-lstm-pytorch/checkpoints/1ts-kbest30-mlp/LSTNet exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "\n",
      "  | Name      | Type    | Params\n",
      "--------------------------------------\n",
      "0 | conv1     | Conv2d  | 6.0 K \n",
      "1 | GRU1      | GRU     | 18.8 K\n",
      "2 | dropout   | Dropout | 0     \n",
      "3 | GRUskip   | GRU     | 720   \n",
      "4 | linear1   | Linear  | 2.6 K \n",
      "5 | highway   | Linear  | 8     \n",
      "6 | criterion | MSELoss | 0     \n",
      "--------------------------------------\n",
      "28.1 K    Trainable params\n",
      "0         Non-trainable params\n",
      "28.1 K    Total params\n",
      "0.112     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e697ba93471f410a97d0b5ac8cb638f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/damso/opt/anaconda3/envs/venv/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/Users/damso/opt/anaconda3/envs/venv/lib/python3.8/site-packages/torch/nn/functional.py:1967: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "/Users/damso/opt/anaconda3/envs/venv/lib/python3.8/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([128, 1])) that is different to the input size (torch.Size([128, 31])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/Users/damso/opt/anaconda3/envs/venv/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd4f30aadccb4af490f19fb40ff98b27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/damso/opt/anaconda3/envs/venv/lib/python3.8/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([71, 1])) that is different to the input size (torch.Size([71, 31])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87137e1242d2437e94047d6cf360a5cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/damso/opt/anaconda3/envs/venv/lib/python3.8/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([114, 1])) that is different to the input size (torch.Size([114, 31])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21855b2285a84073a445ea628b88cbb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a041ac3ce354150bfcccb8de38facdc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab0c4bbd430b40aa929962c4fdf804af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "028cb50a3ffe45e2922a65980aa5e717",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9868438f22d4b8c85c319c2b96c0e41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31be063a1c0843f3a9851aee6b6daec4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04c9af6eaa3e44ef955e61b8d495a988",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9955ac042924f9997c46b86c2e809b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52acb1f9cb0d40018e99e32c31cca3cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "968122724c144986a0047dfc4e231ff7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d341b7d396c04ecb8c04658bc71e604b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/damso/opt/anaconda3/envs/venv/lib/python3.8/site-packages/lightning/pytorch/trainer/call.py:54: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60dbfe3a0603463eac801538118b5636",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▂▂▂▃▃▄▄▄▄▅▅▅▅▆▆▇▇▇▇██</td></tr><tr><td>train/corr</td><td>▁▄▅▆▇▇▇█████</td></tr><tr><td>train/loss</td><td>█▆▄▃▃▂▂▂▂▁▁▁</td></tr><tr><td>train/rse</td><td>█▆▄▄▃▂▂▂▂▁▁▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▂▂▂▂▃▃▄▄▄▄▅▅▅▅▆▆▇▇▇▇██</td></tr><tr><td>val/corr</td><td>▁▄▆▆▆▇▇▇████</td></tr><tr><td>val/loss</td><td>█▇▆▅▄▄▅▅▄▃▁▁</td></tr><tr><td>val/rse</td><td>███▇▅▆▇▇▆▄▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>11</td></tr><tr><td>train/corr</td><td>3.77245</td></tr><tr><td>train/loss</td><td>0.00803</td></tr><tr><td>train/rse</td><td>6.23129</td></tr><tr><td>trainer/global_step</td><td>2303</td></tr><tr><td>val/corr</td><td>3.68455</td></tr><tr><td>val/loss</td><td>0.011</td></tr><tr><td>val/rse</td><td>6.69415</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">1ts-kbest30-mlp-LSTNet</strong> at: <a href='https://wandb.ai/mva-data-challenge/Time-Series%20project/runs/k7e87r0p' target=\"_blank\">https://wandb.ai/mva-data-challenge/Time-Series%20project/runs/k7e87r0p</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>logs/wandb/run-20230327_102550-k7e87r0p/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lstnet_trainer.fit(lstnet, elec_dm)\n",
    "wandb_logger_lstnet.experiment.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**VAR**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means = custom_data.mean(axis=0)\n",
    "stds = custom_data.std(axis=0)\n",
    "\n",
    "normed_data = (custom_data - means) / stds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_lim = math.floor(data_splits['train'] * custom_data.shape[0]) \n",
    "test_lim =  math.floor(data_splits['val'] * custom_data.shape[0]) + train_lim\n",
    "\n",
    "train_data = normed_data[:train_lim]\n",
    "test_data = normed_data[test_lim:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(train_data.shape[1]):\n",
    "    plt.figure(figsize=(15, 4))\n",
    "    plt.plot(train_data[:, i])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_model = VAR(train_data)\n",
    "var_res = var_model.fit(24)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = test_data.shape[0] - (24 + pred_horizon)\n",
    "ypreds = np.zeros((n, pred_horizon))\n",
    "ytrue = np.zeros((n, pred_horizon))\n",
    "\n",
    "for i in range(n):\n",
    "    ypreds[i] = var_res.forecast(test_data[i: i +24], 4)[:, -1]\n",
    "    ytrue[i] = test_data[i + 24: i + 24 + pred_horizon, -1]\n",
    "    \n",
    "var_rse = RSE(ypreds, ytrue)\n",
    "var_corr = CORR(ypreds, ytrue)\n",
    "print(f\"VAR predictions - RSE: {var_rse}, CORR: {var_corr}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
